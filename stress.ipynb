{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1mkPTwSLPddUF77cJg99JGSPwMfLh-DPz",
      "authorship_tag": "ABX9TyN3SEVEBFCGujYQDtsVB7mN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kushalswami20/GitGuyz/blob/main/stress.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M6dopxAiLLxr",
        "outputId": "f1e09b9e-f687-478c-dc5c-ef8e05349665"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Analyzing audio file...\n",
            "Processing file: /content/drive/MyDrive/Music/Color_Out_-_Host.wav\n",
            "\n",
            "Analysis Results:\n",
            "==================================================\n",
            "Dominant Emotion: SAD\n",
            "Stress Level: Low Stress\n",
            "Confidence Score: 26.4%\n",
            "\n",
            "Detailed Emotion Scores:\n",
            "------------------------------\n",
            "Happy   :  24.7% |████\n",
            "Sad     :  26.4% |█████\n",
            "Angry   :  23.3% |████\n",
            "Neutral :  25.6% |█████\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-e10defda728d>:47: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  features['tempo'] = float(self.normalize_value(tempo, 50, 200))  # Normalize between 50-200 BPM\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import librosa\n",
        "import librosa.feature\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "class AudioEmotionAnalyzer:\n",
        "    def __init__(self):\n",
        "        self.emotion_thresholds = {\n",
        "            'happy': {'energy': 0.7, 'tempo': 120},\n",
        "            'sad': {'energy': 0.3, 'tempo': 80},\n",
        "            'angry': {'energy': 0.8, 'tempo': 140},\n",
        "            'neutral': {'energy': 0.5, 'tempo': 100}\n",
        "        }\n",
        "\n",
        "    def normalize_value(self, value, min_val, max_val):\n",
        "        \"\"\"Normalize a value to range 0-1\"\"\"\n",
        "        return np.clip((value - min_val) / (max_val - min_val), 0, 1)\n",
        "\n",
        "    def extract_features(self, file_path):\n",
        "        try:\n",
        "            # Load the audio file\n",
        "            y, sr = librosa.load(file_path, duration=30)\n",
        "\n",
        "            features = {}\n",
        "\n",
        "            # Normalize RMS (Root Mean Square Energy)\n",
        "            rms = librosa.feature.rms(y=y)\n",
        "            features['rms'] = float(np.clip(np.mean(rms) * 10, 0, 1))  # Scale and clip\n",
        "\n",
        "            # Normalize Zero Crossing Rate\n",
        "            zcr = librosa.feature.zero_crossing_rate(y)\n",
        "            features['zero_crossing_rate'] = float(np.clip(np.mean(zcr), 0, 1))\n",
        "\n",
        "            # Normalize Spectral Features\n",
        "            centroid = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
        "            features['spectral_centroid'] = float(self.normalize_value(np.mean(centroid), 0, sr/2))\n",
        "\n",
        "            bandwidth = librosa.feature.spectral_bandwidth(y=y, sr=sr)\n",
        "            features['spectral_bandwidth'] = float(self.normalize_value(np.mean(bandwidth), 0, sr/2))\n",
        "\n",
        "            rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)\n",
        "            features['spectral_rolloff'] = float(self.normalize_value(np.mean(rolloff), 0, sr/2))\n",
        "\n",
        "            # Normalize Tempo\n",
        "            tempo, _ = librosa.beat.beat_track(y=y, sr=sr)\n",
        "            features['tempo'] = float(self.normalize_value(tempo, 50, 200))  # Normalize between 50-200 BPM\n",
        "\n",
        "            # Normalize MFCCs\n",
        "            mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
        "            for i, mfcc in enumerate(mfccs):\n",
        "                features[f'mfcc_{i+1}'] = float(self.normalize_value(np.mean(mfcc), -100, 100))\n",
        "\n",
        "            # Normalize Energy\n",
        "            energy = np.sum(y**2) / len(y)\n",
        "            features['energy'] = float(self.normalize_value(energy, 0, np.max(y**2)))\n",
        "\n",
        "            return features\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing file: {str(e)}\")\n",
        "            return None\n",
        "\n",
        "    def analyze_emotion(self, features):\n",
        "        if features is None:\n",
        "            return None\n",
        "\n",
        "        emotion_scores = {}\n",
        "\n",
        "        for emotion, thresholds in self.emotion_thresholds.items():\n",
        "            # Calculate base scores (0-1 range)\n",
        "            energy_score = 1 - abs(features['energy'] - thresholds['energy'])\n",
        "            tempo_score = 1 - abs(features['tempo'] - self.normalize_value(thresholds['tempo'], 50, 200))\n",
        "\n",
        "            # Calculate additional features (0-1 range)\n",
        "            mfcc_scores = [features[f'mfcc_{i}'] for i in range(1, 14)]\n",
        "            mfcc_variation = np.clip(np.std(mfcc_scores), 0, 1)\n",
        "            spectral_score = features['spectral_centroid']\n",
        "\n",
        "            # Combine scores with weights\n",
        "            emotion_scores[emotion] = np.clip(\n",
        "                energy_score * 0.3 +\n",
        "                tempo_score * 0.3 +\n",
        "                (1 - mfcc_variation) * 0.2 +\n",
        "                spectral_score * 0.2,\n",
        "                0, 1\n",
        "            ) * 100  # Convert to percentage\n",
        "\n",
        "        # Normalize scores to ensure they sum to 100%\n",
        "        total = sum(emotion_scores.values())\n",
        "        if total > 0:\n",
        "            emotion_scores = {k: (v/total * 100) for k, v in emotion_scores.items()}\n",
        "\n",
        "        stress_level = self._calculate_stress_level(features)\n",
        "        dominant_emotion = max(emotion_scores.items(), key=lambda x: x[1])[0]\n",
        "\n",
        "        return {\n",
        "            'dominant_emotion': dominant_emotion,\n",
        "            'emotion_scores': emotion_scores,\n",
        "            'stress_level': stress_level,\n",
        "            'confidence': max(emotion_scores.values())\n",
        "        }\n",
        "\n",
        "    def _calculate_stress_level(self, features):\n",
        "        # Calculate stress score (0-1 range)\n",
        "        stress_score = np.clip(\n",
        "            features['spectral_rolloff'] * 0.4 +\n",
        "            features['zero_crossing_rate'] * 0.3 +\n",
        "            features['energy'] * 0.3,\n",
        "            0, 1\n",
        "        )\n",
        "\n",
        "        if stress_score > 0.7:\n",
        "            return \"High Stress\"\n",
        "        elif stress_score > 0.4:\n",
        "            return \"Moderate Stress\"\n",
        "        else:\n",
        "            return \"Low Stress\"\n",
        "\n",
        "    def analyze_audio_file(self, file_path):\n",
        "        if not os.path.exists(file_path):\n",
        "            return {\"error\": \"File not found\"}\n",
        "\n",
        "        print(f\"Processing file: {file_path}\")\n",
        "        features = self.extract_features(file_path)\n",
        "\n",
        "        if features is None:\n",
        "            return {\"error\": \"Error processing audio file\"}\n",
        "\n",
        "        analysis = self.analyze_emotion(features)\n",
        "        return analysis\n",
        "\n",
        "def format_results(result):\n",
        "    if \"error\" in result:\n",
        "        return f\"Error: {result['error']}\"\n",
        "\n",
        "    output = \"\\nAnalysis Results:\\n\" + \"=\"*50 + \"\\n\"\n",
        "    output += f\"Dominant Emotion: {result['dominant_emotion'].upper()}\\n\"\n",
        "    output += f\"Stress Level: {result['stress_level']}\\n\"\n",
        "    output += f\"Confidence Score: {result['confidence']:.1f}%\\n\\n\"\n",
        "\n",
        "    output += \"Detailed Emotion Scores:\\n\" + \"-\"*30 + \"\\n\"\n",
        "    for emotion, score in result['emotion_scores'].items():\n",
        "        bars = \"█\" * int(score/5)  # Visual representation of score\n",
        "        output += f\"{emotion.capitalize():8}: {score:5.1f}% |{bars}\\n\"\n",
        "\n",
        "    return output\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    analyzer = AudioEmotionAnalyzer()\n",
        "    file_path = \"/content/drive/MyDrive/Music/Color_Out_-_Host.wav\"\n",
        "\n",
        "    print(\"\\nAnalyzing audio file...\")\n",
        "    result = analyzer.analyze_audio_file(file_path)\n",
        "    print(format_results(result))"
      ]
    }
  ]
}